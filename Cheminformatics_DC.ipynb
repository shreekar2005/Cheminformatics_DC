{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreekar2005/Cheminformatics_DC/blob/main/Cheminformatics_DC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJu1ZAPXQGiu"
      },
      "source": [
        "#Loading Tox21 Dense features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq_DhKYRbDgn",
        "outputId": "ffd5e90e-0d71-4be3-8347-4a1f8f62b057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"changes from shreekar\")\n",
        "\n",
        "\n",
        "#load data with urls\n",
        "url1='https://raw.githubusercontent.com/shreekar2005/Cheminformatics_DC/refs/heads/main/DATASET_sorted/TRAIN_dense/tox21_dense_train.csv'\n",
        "url2='https://raw.githubusercontent.com/shreekar2005/Cheminformatics_DC/refs/heads/main/DATASET_sorted/TRAIN_dense/tox21_labels_train.csv'\n",
        "url3='https://raw.githubusercontent.com/shreekar2005/Cheminformatics_DC/refs/heads/main/DATASET_sorted/TEST_dense/tox21_dense_test.csv'\n",
        "url4='https://raw.githubusercontent.com/shreekar2005/Cheminformatics_DC/refs/heads/main/DATASET_sorted/TEST_dense/tox21_labels_test.csv'\n",
        "train_features = pd.read_csv(url1)\n",
        "train_labels = pd.read_csv(url2)\n",
        "test_features = pd.read_csv(url3)\n",
        "test_labels = pd.read_csv(url4)\n",
        "\n",
        "# List of target labels (Ensure these are correct)\n",
        "target_labels = ['NR.AhR', 'NR.AR', 'NR.AR.LBD', 'NR.Aromatase', 'NR.ER', 'NR.ER.LBD',\n",
        "                 'NR.PPAR.gamma', 'SR.ARE', 'SR.ATAD5', 'SR.HSE', 'SR.MMP', 'SR.p53']\n",
        "\n",
        "# Select only dense numerical features (Exclude non-numeric columns)\n",
        "dense_features = train_features.select_dtypes(include=['int64', 'float64']).columns.tolist() # name of dense features\n",
        "\n",
        "X_train = train_features[dense_features].values  # Extract only numerical features\n",
        "# y_train = train_labels[target_labels].values     # Extract corresponding target labels\n",
        "\n",
        "X_test = test_features[dense_features].values\n",
        "# y_test = test_labels[target_labels].values\n",
        "\n",
        "# Normalization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert NaN values to 0 in labels\n",
        "train_labels[target_labels] = train_labels[target_labels].fillna(0)\n",
        "test_labels[target_labels] = test_labels[target_labels].fillna(0)\n",
        "\n",
        "# Ensure all values are either 0 or 1\n",
        "train_labels[target_labels] = train_labels[target_labels].clip(0, 1)\n",
        "test_labels[target_labels] = test_labels[target_labels].clip(0, 1)\n",
        "'''\n",
        "what does .clip(0,1) do ?\n",
        "If an element is:\n",
        "Less than 0, it is set to 0.\n",
        "Greater than 1, it is set to 1.\n",
        "Between 0 and 1, it remains unchanged\n",
        "'''\n",
        "\n",
        "# Convert labels to numpy arrays and PyTorch tensors\n",
        "y_train = train_labels[target_labels].values\n",
        "y_test = test_labels[target_labels].values\n",
        "\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_torch = torch.tensor(y_train, dtype=torch.float32)  # Multi-label classification\n",
        "\n",
        "X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_torch = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# Move tensors to GPU (if available)\n",
        "X_train_torch, y_train_torch = X_train_torch.to(device), y_train_torch.to(device)\n",
        "X_test_torch, y_test_torch = X_test_torch.to(device), y_test_torch.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gh0wiulsr4_"
      },
      "source": [
        "#NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvthDxYFswes"
      },
      "source": [
        "building model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N9LOhR6tsuhG"
      },
      "outputs": [],
      "source": [
        "class neural_network(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(neural_network, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 12)  # 12 neurons for 12 labels\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()  # Sigmoid for multi-label classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))  # Sigmoid for multi-label probabilities\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tie0nwuts6BJ"
      },
      "source": [
        "training model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42cPfo6gs82_",
        "outputId": "12a149e7-ef3b-490a-fecf-c39ed13def5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6713\n",
            "Epoch 10, Loss: 0.3579\n",
            "Epoch 20, Loss: 0.2373\n",
            "Epoch 30, Loss: 0.1946\n",
            "Epoch 40, Loss: 0.1774\n"
          ]
        }
      ],
      "source": [
        "model1 = neural_network(X_train.shape[1]).to(device)\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for multi-label classification\n",
        "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(50):  # Train for 50 epochs\n",
        "    model1.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model1(X_train_torch)\n",
        "    loss = criterion(outputs, y_train_torch)  # Loss computed for all 12 labels\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JyftX_ctBx1"
      },
      "source": [
        "validating model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j15bFN5stDtl",
        "outputId": "8ce30419-434d-4f7d-f64a-c7f3b014e04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2064\n",
            "\n",
            "Accuracy for each label:\n",
            "NR.AhR: 0.8872\n",
            "NR.AR: 0.9815\n",
            "NR.AR.LBD: 0.9876\n",
            "NR.Aromatase: 0.9397\n",
            "NR.ER: 0.9212\n",
            "NR.ER.LBD: 0.9691\n",
            "NR.PPAR.gamma: 0.9521\n",
            "SR.ARE: 0.8563\n",
            "SR.ATAD5: 0.9413\n",
            "SR.HSE: 0.9660\n",
            "SR.MMP: 0.8980\n",
            "SR.p53: 0.9366\n"
          ]
        }
      ],
      "source": [
        "model1.eval()\n",
        "with torch.no_grad():\n",
        "    # X_test_torch, y_test_torch = X_test_torch.to(device), y_test_torch.to(device)\n",
        "    test_outputs = model1(X_test_torch)\n",
        "    test_loss = criterion(test_outputs, y_test_torch)\n",
        "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "# Convert outputs to numpy for accuracy calculation\n",
        "test_outputs_np = test_outputs.cpu().numpy()\n",
        "y_test_np = y_test_torch.cpu().numpy()\n",
        "\n",
        "# ===== Step 8: Compute Accuracy for Each Label =====\n",
        "threshold = 0.5  # Convert probabilities to binary (0 or 1)\n",
        "test_preds = (test_outputs_np >= threshold).astype(int)\n",
        "\n",
        "print(\"\\nAccuracy for each label:\")\n",
        "for i, label in enumerate(target_labels):\n",
        "    acc = accuracy_score(y_test_np[:, i], test_preds[:, i])\n",
        "    print(f\"{label}: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQvBW4BusOkz"
      },
      "source": [
        "#KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "71MJULV4ocnh"
      },
      "outputs": [],
      "source": [
        "class KNNClassifier:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = np.array(X_train)\n",
        "        self.y_train = np.array(y_train)\n",
        "\n",
        "    def _euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2, axis=1))  # Vectorized distance\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test = np.array(X_test)\n",
        "        predictions = []\n",
        "\n",
        "        for x in X_test:\n",
        "            # Compute distances from test point to all training points\n",
        "            distances = self._euclidean_distance(self.X_train, x)\n",
        "            # Get indices of k nearest neighbors\n",
        "            k_indices = np.argsort(distances)[:self.k]\n",
        "            # Get corresponding labels\n",
        "            k_labels = self.y_train[k_indices]\n",
        "\n",
        "            # Majority voting for multi-label classification (mean method)\n",
        "            y_pred = (np.mean(k_labels, axis=0) >= 0.5).astype(int)\n",
        "            predictions.append(y_pred)\n",
        "\n",
        "        return np.array(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W_448ySqzBh4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ee285c39-bd98-479f-e0a9-9937228ffe03"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'columns'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c2ba107504d9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Compute accuracy per label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlabel_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabel_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
          ]
        }
      ],
      "source": [
        "# Train custom KNN model\n",
        "knn = KNNClassifier(k=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Compute accuracy per label\n",
        "label_accuracies = {}\n",
        "for i, col in enumerate(y_train.columns):\n",
        "    correct = np.sum(y_train[col].values == y_pred[:, i])\n",
        "    label_accuracies[col] = correct / len(y_train)\n",
        "\n",
        "# Print accuracy for each label\n",
        "for label, acc in label_accuracies.items():\n",
        "    print(f\"Accuracy for {label}: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41-Z9Q_5hsyB"
      },
      "source": [
        "# trying on tox21 sparse features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH4T7aLVhwcc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.io import mmread\n",
        "\n",
        "# Updated URL (If confirmed it is the wrong file, get the new URL)\n",
        "# If the intended format is `csv`, reading it directly with pandas should resolve the issue\n",
        "# example: url = 'https://github.com/shreekar2005/Cheminformatics_DC/raw/main/DATASET_sorted/TRAIN_sparse/tox21_sparse_train.csv'\n",
        "#           df = pd.read_csv(url)\n",
        "url = 'https://raw.githubusercontent.com/shreekar2005/Cheminformatics_DC/refs/heads/main/DATASET_sorted/TRAIN_sparse/tox21_sparse_train.mtx'\n",
        "\n",
        "try:\n",
        "    # Attempt to read as Matrix Market file\n",
        "    Matrix = mmread(url)\n",
        "    B = Matrix.todense()\n",
        "    df = pd.DataFrame(B, range(1, B.shape[0] + 1), range(1, B.shape[1] + 1))\n",
        "    print(df)\n",
        "\n",
        "except ValueError as e:\n",
        "    if \"Not a Matrix Market file\" in str(e):\n",
        "        # If it's not a Matrix Market file, try reading as a CSV with pandas\n",
        "        print(\"File is not in Matrix Market format. Trying to read as CSV.\")\n",
        "        df = pd.read_csv(url)\n",
        "        print(df)\n",
        "    else:\n",
        "        # If another error occurred, raise it\n",
        "        raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdCbGHu-itKU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}