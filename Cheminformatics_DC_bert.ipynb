{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/shreekar2005/Cheminformatics_DC/blob/main/Cheminformatics_DC_bert.ipynb",
      "authorship_tag": "ABX9TyOUcxApQorkJMxxO5cK94rT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreekar2005/Cheminformatics_DC/blob/main/Cheminformatics_DC_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER2Ye-xKlT6S",
        "outputId": "a78be9ef-ea86-4886-a88b-393b71a1a750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272776\n",
            "(12060, 801) (12060, 272776)\n",
            "(12060, 1644)\n",
            "(12060, 12)\n",
            "torch.Size([12060, 1644])\n",
            "torch.Size([647, 1644])\n",
            "NR.AhR: Training valid samples = 8441, Testing valid samples = 610\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Data using Pandas\n",
        "y_tr = pd.read_csv('drive/MyDrive/DATASET/tox21_labels_train.csv.gz', index_col=0, compression=\"gzip\")\n",
        "y_te = pd.read_csv('drive/MyDrive/DATASET/tox21_labels_test.csv.gz', index_col=0, compression=\"gzip\")\n",
        "x_tr_dense = pd.read_csv('drive/MyDrive/DATASET/tox21_dense_train.csv.gz', index_col=0, compression=\"gzip\").values\n",
        "x_te_dense = pd.read_csv('drive/MyDrive/DATASET/tox21_dense_test.csv.gz', index_col=0, compression=\"gzip\").values\n",
        "x_tr_sparse = io.mmread('drive/MyDrive/DATASET/tox21_sparse_train.mtx.gz').tocsc()\n",
        "x_te_sparse = io.mmread('drive/MyDrive/DATASET/tox21_sparse_test.mtx.gz').tocsc()\n",
        "\n",
        "# filter out very sparse features\n",
        "sparse_col_idx = ((x_tr_sparse > 0).mean(0) > 0.05).A.ravel()\n",
        "print(sparse_col_idx.size)\n",
        "x_tr = np.hstack([x_tr_dense, x_tr_sparse[:, sparse_col_idx].toarray()])\n",
        "x_te = np.hstack([x_te_dense, x_te_sparse[:, sparse_col_idx].toarray()])\n",
        "\n",
        "print(x_tr_dense.shape, x_tr_sparse.shape)\n",
        "print(x_tr.shape)\n",
        "print(y_tr.shape)\n",
        "# Convert to PyTorch tensors on CPU\n",
        "device = torch.device(\"cpu\")\n",
        "x_tr_tensor = torch.tensor(x_tr, dtype=torch.float32)\n",
        "x_te_tensor = torch.tensor(x_te, dtype=torch.float32)\n",
        "print(x_tr_tensor.shape)\n",
        "print(x_te_tensor.shape)\n",
        "# Define Transformer Model (CPU version)\n",
        "class TabularTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim=32, num_heads=2, num_layers=2, num_classes=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = self.embedding(x).unsqueeze(1)\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        x = self.transformer(x)\n",
        "        cls_output = x[:, 0, :]\n",
        "        return self.classifier(cls_output).squeeze(-1)\n",
        "\n",
        "# Store all confusion matrices and AUCs\n",
        "conf_matrices = {}\n",
        "aucs = {}\n",
        "\n",
        "# Train and evaluate for each target\n",
        "# Train and evaluate for each target\n",
        "for target in y_tr.columns:\n",
        "    # Filter rows with non-missing labels\n",
        "    rows_tr = y_tr[target].notna().values\n",
        "    rows_te = y_te[target].notna().values\n",
        "\n",
        "    print(f\"{target}: Training valid samples = {sum(rows_tr)}, Testing valid samples = {sum(rows_te)}\")\n",
        "\n",
        "    if sum(rows_tr) == 0 or sum(rows_te) == 0:\n",
        "        print(f\"Skipping {target} due to no valid samples\")\n",
        "        continue\n",
        "\n",
        "    # Prepare data\n",
        "    y_tr_tensor = torch.tensor(y_tr[target][rows_tr].values, dtype=torch.float32)\n",
        "    train_dataset = TensorDataset(x_tr_tensor[rows_tr], y_tr_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Initialize model\n",
        "    model = TabularTransformer(input_dim=x_tr.shape[1], num_classes=1)\n",
        "    criterion = nn.BCEWithLogitsLoss() # This loss function combines a sigmoid layer with BCELoss\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(10):\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(x_te_tensor[rows_te]).squeeze().numpy()\n",
        "\n",
        "    # Check for and handle NaN values in test_outputs and y_te[target][rows_te]\n",
        "    valid_indices = np.isfinite(test_outputs) & y_te[target][rows_te].notna().values\n",
        "    test_outputs = test_outputs[valid_indices]\n",
        "    true_labels = y_te[target][rows_te].values[valid_indices]\n",
        "\n",
        "    # Compute AUC only if there are valid samples\n",
        "    if len(true_labels) > 0:\n",
        "        auc_te = roc_auc_score(true_labels, test_outputs)\n",
        "        aucs[target] = auc_te\n",
        "        print(f\"{target}: AUC = {auc_te:.5f}\")\n",
        "\n",
        "        # Confusion matrix\n",
        "        p_te_pred = (test_outputs > 0.5).astype(int)\n",
        "        conf_matrices[target] = confusion_matrix(true_labels, p_te_pred)\n",
        "    else:\n",
        "        print(f\"Skipping {target} due to no valid samples after NaN removal\")\n",
        "\n",
        "# Plot confusion matrices\n",
        "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "for i, (target, cm) in enumerate(conf_matrices.items()):\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=[\"Negative\", \"Positive\"],\n",
        "                yticklabels=[\"Negative\", \"Positive\"],\n",
        "                ax=axes[i])\n",
        "    axes[i].set_title(f\"{target} (AUC = {aucs[target]:.2f})\")\n",
        "    axes[i].set_xlabel(\"Predicted\")\n",
        "    axes[i].set_ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZVvmhI89F-d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}